{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ariaberlian/rbm_sr/blob/main/rbm_sr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1niMNjgRwd2"
   },
   "outputs": [],
   "source": [
    "# Python v3.6.12\n",
    "\n",
    "##### Run This to Install #####\n",
    "\n",
    "# ! pip install requirements.txt\n",
    "\n",
    "## !git clone https://github.com/albertbup/deep-belief-network.git\n",
    "## !pip install -r \"deep-belief-network/requirements.txt\"\n",
    "## !mv \"deep-belief-network\" \"deep_belief_network\"\n",
    "\n",
    "## \"\"\"\n",
    "## - add this to dbn/tensorflow/models.py:\n",
    "##     import tensorflow._api.v2.compat.v1 as tf\n",
    "##     tf.disable_v2_behavior()\n",
    "## \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9E9apHoc70M",
    "outputId": "3b957557-10ce-46ea-8301-b79e3c096a3b"
   },
   "outputs": [],
   "source": [
    "# from deep_belief_network.dbn.tensorflow.models import UnsupervisedDBN # use \"from dbn.tensorflow import SupervisedDBNClassification\" for computations on TensorFlow\n",
    "from deep_belief_network.dbn.tensorflow.models import SupervisedDBNRegression\n",
    "from utils.data_processing import DataProcessing\n",
    "from utils.image_file_util import *\n",
    "from utils.scoring import *\n",
    "from utils.visualizer import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import multiprocessing\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LV1RtFIhUdV"
   },
   "source": [
    "## DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i, row, model_name, model, interpolation_factor, patch_size, stride,data_train_size, dp: DataProcessing):\n",
    "\n",
    "    test_var = row[f\"test{i}\"]\n",
    "    test_ref_var = row[f\"test{i}_ref\"]\n",
    "    test_image = load_image(f\"test/{test_var}\")\n",
    "    test_reference_image = load_image(f\"test/{test_ref_var}\")\n",
    "    model = model.load(f\"model/{model_name}.h5\")\n",
    "    \n",
    "    print(f\"Testing model: {model_name}...\")\n",
    "    interpolated_test = dp.interpolate(test_image, interpolation_factor)\n",
    "\n",
    "    test_patches = dp.get_patches(interpolated_test, patch_size, stride)\n",
    "    norm, int_test_dct_ex = dp.normalize_for_rbm(test_patches[:test_patches.shape[0]])\n",
    "    if data_train_size < test_patches.shape[0]:\n",
    "        norm = dp.normalize_for_rbm(test_patches[:data_train_size])\n",
    "\n",
    "    test_patches_flat = dp.preprocess_for_rbm(norm)\n",
    "    norm=None\n",
    "\n",
    "    result_flat = model.predict(test_patches_flat)\n",
    "    result_flat = dp.proccess_output(test_patches_flat, result_flat, interpolation_factor)\n",
    "\n",
    "    result_patches, recons_dct_ex = dp.inverse_preprocess(\n",
    "        result_flat, (patch_size[0], patch_size[1], 3)\n",
    "    )\n",
    "\n",
    "    reconstruct_image = dp.reconstruct_from_patches(\n",
    "        result_patches, original_shape=test_reference_image.shape, patch_size=patch_size, stride=stride)\n",
    "    \n",
    "    visualize4image(test_image, \"Test Image\", interpolated_test, \"Interpolated Test Image\",\n",
    "                     reconstruct_image, \"Reconstructed Image\", test_reference_image, \"Reference Image\")\n",
    "    \n",
    "    visualize4Histogram(test_image, \"Test Image\", interpolated_test, \"Interpolated Test Image\",\n",
    "                     reconstruct_image, \"Reconstructed Image\", test_reference_image, \"Reference Image\")\n",
    "    \n",
    "    visualize_dct(int_test_dct_ex, \"Interpolated Test\")\n",
    "    visualize_dct(recons_dct_ex, \"Reconstructed Image\")\n",
    "\n",
    "    norm, refs_dct_ex = dp.normalize_for_rbm(dp.get_patches(test_reference_image,patch_size,stride))\n",
    "    visualize_dct(refs_dct_ex, \"Reference Image\")\n",
    "\n",
    "    refs_flat = dp.preprocess_for_rbm(norm)\n",
    "\n",
    "    psnr_baseline = calculate_psnr(test_reference_image, interpolated_test)\n",
    "    ssim_baseline = calculate_ssim(test_reference_image, interpolated_test)*100\n",
    "    rmse_baseline = calculate_rmse(refs_flat, test_patches_flat)\n",
    "    psnr = calculate_psnr(test_reference_image, reconstruct_image)\n",
    "    ssim = calculate_ssim(test_reference_image, reconstruct_image)*100\n",
    "    rmse = calculate_rmse(refs_flat,result_flat)\n",
    "\n",
    "    print(f\"PSNR {i} Interpolated: {psnr_baseline:,.3f} dB\")\n",
    "    print(f\"SSIM {i} Interpolated: {ssim_baseline:,.3f} %\")\n",
    "    print(f\"RMSE {i} Interpolated {rmse_baseline}\")\n",
    "    print(f\"PSNR {i}: {psnr:,.3f} dB\")\n",
    "    print(f\"SSIM {i}: {ssim:,.3f} %\")\n",
    "    print(f\"RMSE {i}: {rmse}\")\n",
    "    \n",
    "    # Cleanup: explicitly delete all variables\n",
    "    del test_image, test_reference_image, interpolated_test, test_patches, test_patches_flat\n",
    "    del result_flat, result_patches, reconstruct_image, refs_flat, norm\n",
    "    gc.collect()\n",
    "\n",
    "    return psnr_baseline,ssim_baseline,psnr,ssim,rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file Excel\n",
    "excel_name = \"Experimentation.xlsx\"\n",
    "exp_df = pd.read_excel(excel_name, engine=\"openpyxl\")\n",
    "\n",
    "def main(idx, row):\n",
    "    try:\n",
    "        # Baca parameter dari Excel untuk baris ini\n",
    "        train = row[\"train\"]\n",
    "        fine_image = row[\"fine_tuning\"]\n",
    "        fine_label = row[\"label\"]\n",
    "\n",
    "        train_resolution = row['train_res']\n",
    "\n",
    "        interpolation_factor = row['factor']\n",
    "        patch_size = (row['patch_size'], row['patch_size'])\n",
    "        stride = (row['stride'], row['stride'])\n",
    "        data_train_size = row[\"data_train_size\"]\n",
    "\n",
    "        lr = 0.001\n",
    "        epoch = 500\n",
    "        epoch_fine = 100\n",
    "        layers = [int(layer) for layer in str(row['layers']).split(\",\")]\n",
    "        batch_size = row['batch_size']\n",
    "        activation_function = 'sigmoid'\n",
    "\n",
    "        model_name = f\"model_{train}_{train_resolution}_x{interpolation_factor}_p{patch_size[0]}_s{stride[0]}_l{layers}\"\n",
    "        print(f\"\\nTraining model: {model_name}\")\n",
    "\n",
    "        #### Load Data and Preprocess ####\n",
    "        dp = DataProcessing()\n",
    "\n",
    "        training_image = load_image(f\"train/{train}\")\n",
    "        # visualize_image(training_image, \"Pre-Training Image\")\n",
    "        train_patches = dp.get_patches(training_image, patch_size=patch_size, stride=stride)\n",
    "        norm, _ = dp.normalize_for_rbm(train_patches[:train_patches.shape[0]])\n",
    "        if data_train_size < train_patches.shape[0]:\n",
    "            norm = dp.normalize_for_rbm(train_patches[:data_train_size])\n",
    "\n",
    "        X_pretrain = dp.preprocess_for_rbm(norm)\n",
    "\n",
    "        del train_patches, training_image, norm\n",
    "        gc.collect()\n",
    "\n",
    "        fine_image = dp.interpolate(load_image(f'train/{fine_image}'), 2)\n",
    "        label = load_image(f'train/{fine_label}')\n",
    "\n",
    "        visualize_histogram_compare(fine_image, label, \"Interpolated Fine Tuning Image\", \"Label Image\")\n",
    "\n",
    "        fine_patches = dp.get_patches(fine_image, patch_size=patch_size, stride=stride)\n",
    "        norm, _ = dp.normalize_for_rbm(fine_patches[:fine_patches.shape[0]])\n",
    "        if data_train_size < fine_patches.shape[0]:\n",
    "            norm = dp.normalize_for_rbm(fine_patches[:data_train_size])\n",
    "        X = dp.preprocess_for_rbm(norm)\n",
    "\n",
    "        del fine_patches, fine_image, norm\n",
    "        gc.collect()\n",
    "\n",
    "        label_patches = dp.get_patches(label, patch_size=patch_size, stride=stride)\n",
    "        norm, _ = dp.normalize_for_rbm(label_patches[:label_patches.shape[0]])\n",
    "        if data_train_size < label_patches.shape[0]:\n",
    "            norm = dp.normalize_for_rbm(label_patches[:data_train_size])\n",
    "        y = dp.preprocess_for_rbm(norm)\n",
    "\n",
    "        del label, label_patches, norm\n",
    "        gc.collect()\n",
    "\n",
    "        # #### Model Configuration ####\n",
    "        dbn = SupervisedDBNRegression(\n",
    "                    hidden_layers_structure=layers,\n",
    "                    batch_size=batch_size,\n",
    "                    learning_rate_rbm=lr,\n",
    "                    n_epochs_rbm=epoch,\n",
    "                    activation_function=activation_function,\n",
    "                    optimization_algorithm='sgd',\n",
    "                    learning_rate=lr,\n",
    "                    n_iter_backprop=epoch_fine,\n",
    "        )\n",
    "\n",
    "        #### Train the Model ####\n",
    "        if not(os.path.exists(f\"model/{model_name}.h5\")):\n",
    "            print(f\"Starting training for model: {model_name}\")\n",
    "            start_time = time.time()\n",
    "            dbn.fit(X_pretrain,X,y)\n",
    "            end_time = time.time()\n",
    "\n",
    "            print(\"Training time: \", (end_time-start_time))\n",
    "            dbn.save(f\"model/{model_name}.h5\")\n",
    "\n",
    "            print(f\"Model has been saved: {model_name}\")\n",
    "            exp_df.at[idx, \"training_time\"] = (end_time-start_time)\n",
    "\n",
    "            del X_pretrain, X, y\n",
    "            gc.collect()\n",
    "        \n",
    "        else:\n",
    "            print(\"Model alrady exist!\")\n",
    "\n",
    "        #### Testing and Saving Results ####\n",
    "        for i in range(1, 6):\n",
    "            psnr_baseline, ssim_baseline, psnr, ssim,rmse = test(i, row, model_name, dbn, interpolation_factor, patch_size,stride,data_train_size, dp)\n",
    "            # Save results to DataFrame\n",
    "            exp_df.at[idx, f\"b_psnr{i}\"] = psnr_baseline\n",
    "            exp_df.at[idx, f\"b_ssim{i}\"] = ssim_baseline\n",
    "            exp_df.at[idx, f\"psnr{i}\"] = psnr\n",
    "            exp_df.at[idx, f\"ssim{i}\"] = ssim\n",
    "            exp_df.at[idx, f\"rmse{i}\"] = rmse\n",
    "            exp_df.to_excel(excel_name, index=False)\n",
    "\n",
    "        print(f\"Finished processing row {idx+1}/{len(exp_df)} with model {model_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx+1}: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Ensure all variables are deleted in the end\n",
    "        del train, fine_label, train_resolution, interpolation_factor\n",
    "        del patch_size, stride, data_train_size, lr, epoch, layers, batch_size, activation_function, model_name\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "specific_index = 1\n",
    "\n",
    "# Process the specific row\n",
    "if specific_index in exp_df.index:\n",
    "    row = exp_df.loc[specific_index]\n",
    "    main(specific_index, row) \n",
    "else:\n",
    "    print(f\"Index {specific_index} not found in the DataFrame.\")\n",
    "\n",
    "\n",
    "# for idx, row in tqdm(exp_df.iterrows(), total=len(exp_df), desc=\"Processing Rows\"):\n",
    "    # main(idx,row)\n",
    "\n",
    "\n",
    "# print(\"All rows processed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training DBN\n",
    "# def train(model, input : np.ndarray, model_name : str, repetitions: int, beta:float, interpolation_factor:float):\n",
    "#     dp = DataProcessing()\n",
    "\n",
    "#     visualize_histogram(input, title=f\"Training Image\")\n",
    "\n",
    "#     curr_rep = 1\n",
    "#     print(\"Repetisi saat ini: \", curr_rep)\n",
    "\n",
    "#     model.fit(input)\n",
    "#     model.save(f\"model/{model_name}_{curr_rep}.h5\")\n",
    "\n",
    "#     while curr_rep < repetitions:\n",
    "#         model = model.load(f\"model/{model_name}_{curr_rep}.h5\")\n",
    "#         r = model.transform(input)\n",
    "#         print(\"Shape Transformed: \", r.shape)\n",
    "#         input = dp.proccess_output(u=input, r=r, beta=beta, s=interpolation_factor)\n",
    "#         visualize_histogram(input, title=f\"Training Image: After transform ({curr_rep})\")\n",
    "#         r = None\n",
    "\n",
    "#         curr_rep += 1\n",
    "#         print(\"Repetisi saat ini: \", curr_rep )\n",
    "\n",
    "#         model.fit(input)\n",
    "#         model.save(f\"model/{model_name}_{curr_rep}.h5\")\n",
    "\n",
    "# ## Test DBN\n",
    "# def test(test_image, test_reference_image, model, patch_size:tuple, stride:tuple, interpolation_factor:int):\n",
    "#     dp = DataProcessing()\n",
    "\n",
    "#     desired_shape = test_reference_image.shape\n",
    "    \n",
    "#     test_image = dp.interpolate(test_image, interpolation_factor=interpolation_factor)\n",
    "    \n",
    "#     visualize_image(test_image, title=\"Test Image after interpolation\")\n",
    "#     visualize_histogram(test_image, title=\"Test Image after interpolation\", range=(0,256))\n",
    "#     psnr_baseline_value = calculate_psnr(test_reference_image, test_image)\n",
    "#     ssim_baseline_value = calculate_ssim(test_reference_image, test_image)*100\n",
    "\n",
    "#     psnr_print = f\"PSNR Baseline value: {psnr_baseline_value:,.3f} dB\"\n",
    "#     ssim_print = f\"SSIM Baseline value: {ssim_baseline_value:,.3f}%\"\n",
    "#     print(psnr_print.replace(\".\", \",\"))\n",
    "#     print(ssim_print.replace(\".\", \",\"))\n",
    "\n",
    "#     test_patches = dp.get_patches(test_image,patch_size=patch_size, stride=stride)\n",
    "\n",
    "#     # Process data for rbm\n",
    "#     test_patches = dp.preprocess_for_rbm(test_patches)\n",
    "\n",
    "#     # Infer test to model\n",
    "#     result = model.transform(test_patches)\n",
    "\n",
    "#     test_patches = dp.inverse_preprocess(\n",
    "#         dp.proccess_output(test_patches, result, 1, interpolation_factor),\n",
    "#         original_patch_shape=(patch_size[0], patch_size[1], 3)\n",
    "#         )\n",
    "    \n",
    "#     result = None\n",
    "\n",
    "#     # visualize_patches(test_patches, title=\"Test Patches Example\", visualize_size=(6,6))\n",
    "\n",
    "#     reconstruct_image = dp.reconstruct_from_patches(test_patches, original_shape=desired_shape, patch_size=patch_size, stride=stride)\n",
    "\n",
    "#     test_patches = None\n",
    "\n",
    "#     visualize_histogram_compare(original_image=test_reference_image, reconstruct_image=reconstruct_image)\n",
    "#     psnr_value = calculate_psnr(test_reference_image, reconstruct_image)\n",
    "#     ssim_value = calculate_ssim(test_reference_image, reconstruct_image)*100\n",
    "\n",
    "#     psnr_print = f\"PSNR value: {psnr_value:,.3f} dB\"\n",
    "#     ssim_print = f\"SSIM value: {ssim_value:,.3f}%\"\n",
    "\n",
    "#     print(psnr_print.replace(\".\", \",\"))\n",
    "#     print(ssim_print.replace(\".\", \",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHb0fnnI9sJm",
    "outputId": "a0cfcd81-0c0b-4a1e-da29-7e395f8b64d8"
   },
   "outputs": [],
   "source": [
    "# tracemalloc.start()\n",
    "\n",
    "# #### Patch size and Stride ####\n",
    "# patch_size = (16,16)\n",
    "# stride = (4,4)\n",
    "\n",
    "# #### Load Data ####\n",
    "# train_resolution = 512\n",
    "# test_resolution = 256\n",
    "\n",
    "# dp = DataProcessing()\n",
    "\n",
    "# # Load Pre Training Data\n",
    "# training_image = load_image(\"train/peppers.png\")\n",
    "# visualize_image(training_image, \"Training Image\")\n",
    "\n",
    "# train_patches = dp.get_patches(training_image, patch_size=patch_size, stride=stride)\n",
    "\n",
    "# # Feel free to reduce training set\n",
    "# training_set_num = train_patches.shape[0]\n",
    "\n",
    "# # visualize_patches(train_patches, \"Train patches example\")\n",
    "\n",
    "\n",
    "# X_train = dp.preprocess_for_rbm(train_patches[:training_set_num])\n",
    "\n",
    "# train_patches = None\n",
    "# training_image = None\n",
    "\n",
    "# # Load Fine Tuning Data\n",
    "# fine_image = load_image(\"test/lenna_256.png\")\n",
    "# label_fine = load_image(\"train/lenna.png\")\n",
    "# fine_image = dp.interpolate(fine_image, 2)\n",
    "\n",
    "# fine_patches = dp.get_patches(fine_image, patch_size, stride)\n",
    "# label_patches = dp.get_patches(label_fine, patch_size, stride)\n",
    "\n",
    "# fine_train = dp.preprocess_for_rbm(fine_patches)\n",
    "# label_train = dp.preprocess_for_rbm(label_patches)\n",
    "\n",
    "\n",
    "\n",
    "# #### Training parameter ###\n",
    "# interpolation_factor = 2\n",
    "# beta = 1\n",
    "# Repetitions = 1\n",
    "# lr = 0.01\n",
    "# epoch = 100\n",
    "\n",
    "# layers = [400,200,768]\n",
    "# batch_size = 1024\n",
    "# activation_function = 'relu'\n",
    "\n",
    "# model_name = f\"model_peppers_{train_resolution}_x{interpolation_factor}_p{patch_size[0]}_s{stride[0]}_({layers[0]}_{layers[1]}_{layers[2]})\"\n",
    "\n",
    "# # Models we will use\n",
    "# # dbn = UnsupervisedDBN(hidden_layers_structure=layers,\n",
    "# #                       batch_size=batch_size,\n",
    "# #                       learning_rate_rbm=lr,\n",
    "# #                       n_epochs_rbm=epoch,\n",
    "# #                       activation_function=activation_function,\n",
    "# #                       optimization_algorithm='sgd',)\n",
    "\n",
    "# dbn = SupervisedDBNRegression(\n",
    "#                     hidden_layers_structure=layers,\n",
    "#                       batch_size=batch_size,\n",
    "#                       learning_rate_rbm=lr,\n",
    "#                       n_epochs_rbm=epoch,\n",
    "#                       activation_function=activation_function,\n",
    "#                       optimization_algorithm='sgd',\n",
    "#                                     learning_rate=lr,\n",
    "#                                     n_iter_backprop=200,\n",
    "\n",
    "# )\n",
    "\n",
    "# dbn.fit(X_train, fine_train, label_train)\n",
    "# dbn.save(\"model/hmmm.h5\")\n",
    "# #### Train and Test ####\n",
    "\n",
    "# snapshot1 = tracemalloc.take_snapshot()\n",
    "\n",
    "# # comment this to skip training\n",
    "# # train(\n",
    "# #     model=dbn, \n",
    "# #     input=X_train,\n",
    "# #     model_name=model_name,\n",
    "# #     beta=beta,\n",
    "# #     interpolation_factor=interpolation_factor,\n",
    "# #     repetitions=Repetitions, \n",
    "# # )\n",
    "\n",
    "# snapshot2 = tracemalloc.take_snapshot()\n",
    "# top_stats = snapshot2.compare_to(snapshot1, 'lineno')\n",
    "\n",
    "# print(\"[ Top 10 differences in memory allocation ]\")\n",
    "# for stat in top_stats[:10]:\n",
    "#     print(stat)\n",
    "\n",
    "# # Load Testing Data\n",
    "# print(\"== Test 1 ==\")\n",
    "# test_image = load_image(f\"test/peppers_256.png\")\n",
    "# visualize_image(test_image, title=\"Test Image\")\n",
    "\n",
    "# test_reference_image = load_image(f\"train/peppers.png\")\n",
    "# dbn = dbn.load(f\"model/hmmm.h5\")\n",
    "\n",
    "# test(\n",
    "#     test_image=test_image,\n",
    "#     test_reference_image=test_reference_image,\n",
    "#     model=dbn,\n",
    "#     patch_size=patch_size,\n",
    "#     stride=stride,\n",
    "#     interpolation_factor=interpolation_factor\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# print(\"== Test 2 ==\")\n",
    "# test_image = load_image(f\"test/lenna_256.png\")\n",
    "# visualize_image(test_image, title=\"Test Image\")\n",
    "\n",
    "# test_reference_image = load_image(f\"train/lenna.png\")\n",
    "# dbn = dbn.load(f\"model/{model_name}_{Repetitions}.h5\")\n",
    "\n",
    "# test(\n",
    "#     test_image=test_image,\n",
    "#     test_reference_image=test_reference_image,\n",
    "#     model=dbn,\n",
    "#     patch_size=patch_size,\n",
    "#     stride=stride,\n",
    "#     interpolation_factor=interpolation_factor\n",
    "# )\n",
    "\n",
    "# print(\"== Test 3 ==\")\n",
    "# test_image = load_image(f\"test/{test_resolution}/ct_lung4_{test_resolution}.png\")\n",
    "# visualize_image(test_image, title=\"Test Image\")\n",
    "\n",
    "# test_reference_image = load_image(f\"test/{train_resolution}/ct_lung4_{train_resolution}.png\")\n",
    "# dbn = dbn.load(f\"model/{model_name}_{Repetitions}.h5\")\n",
    "\n",
    "# test(\n",
    "#     test_image=test_image,\n",
    "#     test_reference_image=test_reference_image,\n",
    "#     model=dbn,\n",
    "#     patch_size=patch_size,\n",
    "#     stride=stride,\n",
    "#     interpolation_factor=interpolation_factor\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI5OV_F2Rcgw"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO78JLF4XsGcABgpg/L012g",
   "collapsed_sections": [
    "9PJwKQlYOFWo",
    "ilnhcVI9OKMl",
    "97TIoNNAOO2M",
    "urgQvFpuOVcn",
    "7Hub2KYPOYH1"
   ],
   "include_colab_link": true,
   "mount_file_id": "1StnRFjOmR44zwENLuo85hX_x__mgEbKS",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "rbm_sr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
